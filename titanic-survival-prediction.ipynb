{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#Import data preprocessing modules\nimport numpy as np\nimport numpy.random as random\nimport scipy as sp\nfrom pandas import Series, DataFrame\nimport pandas as pd\n\n# Visualization modules\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nimport seaborn as sns\n%matplotlib inline\n\n# Machine learning module\nimport sklearn","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Read the file\n#Write the code\ndataset = pd.read_csv(\"\")\nprint(dataset.head())\n#Show the first 50 rows\n#Write the code\nselected_rows = dataset.head(50)\nprint(selected_rows)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Observe the data shape\n#Write the code\nprint(dataset.shape)\n#Observe the data information\n#Write the code\nprint(dataset.info())\n#Set seaborn as the default drawing library\n#Write the code\nimport seaborn as sns\nsns.set_theme()\nprint(dataset.isnull().sum())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def bar_chart(feature):\n    #Write the code\n    survived = dataset[dataset['Survived']==1][feature].value_counts()\n    dead = dataset[dataset['Survived']==0][feature].value_counts()\n    df = pd.DataFrame([survived,dead])\n    df.index = ['Survived','Dead']\n    df.plot(kind='bar',stacked=True, figsize=(10,5))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Bar Chat of Survival/Dead Men and Women\n#Write the code\nbar_chart('Sex')\n#Bar Chat of the Cabin of the Survival/Dead Person\n#Write the code\nbar_chart('Pclass')\n#Calculate the number of “NaN” in the columns \n#Write the code\ndataset.isnull().sum()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Name","metadata":{}},{"cell_type":"code","source":"#Observe the Name column\n#Write the code\nprint(dataset['Name'].head())\n#Pick out Mr., Mrs., Miss\ndataset['Title'] = dataset['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n#Count the Number of People by Each Title\n#Write the code\ntitle_counts = dataset['Title'].value_counts()\nprint(title_counts)\n#titlemapping\ntitle_mapping = {\"Mr\": 0, \"Miss\": 1, \"Mrs\": 2, \"Master\": 3, \"Dr\": 3, \"Rev\": 3, \"Col\": 3, \"Major\": 3, \"Mlle\": 3, \"Countess\": 3, \"Ms\": 3, \"Lady\": 3, \"Jonkheer\": 3, \"Don\": 3, \"Dona\": 3, \"Mme\": 3, \"Capt\": 3, \"Sir\": 3}\ndataset['Title'] = dataset['Title'].map(title_mapping)\n#Current dataset\ndataset.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Show the Distribution of Title/Survival and Dead\n#Write the code\nbar_chart('Title')\n#Delete the \"Name\" column\n#Write the code\ndataset = dataset.drop('Name', axis=1) #已經drop過了所以再執行會錯誤\nprint(dataset.head())\n#Current dataframe\ndataset.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Sex","metadata":{}},{"cell_type":"code","source":"#mapping sex\n#Write the code\nsex_mapping = {'male': 0, 'female': 1}\ndataset['Sex'] = dataset['Sex'].map(sex_mapping)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"bar_chart('Sex')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Current dataframe\ndataset.head(100)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Age","metadata":{}},{"cell_type":"code","source":"# fill missing age with median age for each title (Mr, Mrs, Miss, Others)\n#Write the code\ndataset['Age'].fillna(dataset.groupby('Title')['Age'].transform('median'), inplace=True)\ndataset[\"Age\"]\n#Distribution of Age/Survival and Death\nfacet = sns.FacetGrid(dataset, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Age',shade= True)\nfacet.set(xlim=(0, dataset['Age'].max()))\nfacet.add_legend()\n \nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Mapping Function According to the Range of Age \n#Write the code\ndataset.loc[ dataset['Age'] <= 16, 'Age'] = 0\ndataset.loc[ (dataset['Age'] > 16) & (dataset['Age'] <= 26), 'Age'] = 1\ndataset.loc[ (dataset['Age'] > 26) & (dataset['Age'] <= 36), 'Age'] = 2\ndataset.loc[ (dataset['Age'] > 36) & (dataset['Age'] <= 62), 'Age'] = 3\ndataset.loc[ dataset['Age'] > 62, 'Age'] = 4\n#Current dataframe\ndataset.head(20)\n#Bar Chart of Age\n#Write the code\nbar_chart('Age')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Embarkerd","metadata":{}},{"cell_type":"code","source":"#Analyze the Type of Boarding Tickets at Each Boarding Location\n#Write the code\nimport pandas as pd\nPclass1 = dataset[dataset['Pclass']==1]['Embarked'].value_counts()\nPclass2 = dataset[dataset['Pclass']==2]['Embarked'].value_counts()\nPclass3 = dataset[dataset['Pclass']==3]['Embarked'].value_counts()\ndf = DataFrame([Pclass1, Pclass2, Pclass3])\ndf.index = ['1st class','2nd class', '3rd class']\ndf.plot(kind='bar',stacked=True, figsize=(10,5))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Fill Missing Value for Embarked Location\n#Write the code\ndataset['Embarked'] = dataset['Embarked'].fillna('S')\ndataset.head(100)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Mapping Function for the Embarked Location\n#Write the code\nembarked_mapping = {'S':0 , 'C':1, 'Q':2}\ndataset['Embarked'] = dataset['Embarked'].map(embarked_mapping)\ndataset.head(100)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Fare","metadata":{}},{"cell_type":"code","source":"dataset['Fare'].fillna(dataset.groupby('Pclass')['Fare'].transform('median'),inplace=True)\ndataset.head(50)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Distribution of Fare/Survival and Death\nfacet = sns.FacetGrid(dataset, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Fare',shade= True)\nfacet.set(xlim=(0, dataset['Fare'].max()))\nfacet.add_legend()\n \nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Mapping Function According to the Range of Fare\n#Write the code\ndataset.loc[dataset['Fare']<=17, 'Fare'] = 0\ndataset.loc[(dataset['Fare']>17) & (dataset['Fare'] <= 30), 'Fare'] = 1\ndataset.loc[(dataset['Fare']>30) & (dataset['Fare'] <= 100), 'Fare'] = 2\ndataset.loc[dataset['Fare']>100, 'Fare'] = 3","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Current dataframe\ndataset.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Observe the Cabin Number\n#Write the code\ndataset['Cabin'].value_counts()\n#Observe the Cabin Number =>Take out the first letter\n#Write the code\ndataset['Cabin'] = dataset['Cabin'].str[:1]\ndataset['Cabin']\n#Analyze the Number of People in Various Ticket Types and Cabin Types\n#Write the code\nPclass1 = dataset[dataset['Pclass']==1]['Cabin'].value_counts()\nPclass2 = dataset[dataset['Pclass']==2]['Cabin'].value_counts()\nPclass3 = dataset[dataset['Pclass']==3]['Cabin'].value_counts()\ndf = pd.DataFrame([Pclass1, Pclass2, Pclass3])\ndf.index = ['1st class','2nd class', '3rd class']\ndf.plot(kind='bar',stacked=True, figsize=(10,5))\n#Cabin Mapping\n#Write the code\ncabin_mapping = {'A': 0, 'B': 0.4, 'C': 0.8, 'D': 1.2, 'E': 1.6, 'F': 2, 'G': 2.4, 'T': 2.8}\ndataset['Cabin'] = dataset['Cabin'].map(cabin_mapping)\ndataset['Cabin'].head(20)\n#Fill in the Missing Value on the Type of Cabin\n#Write the code\ndataset['Cabin'].fillna(dataset.groupby('Pclass')['Cabin'].transform('median'), inplace=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Current dataframe\ndataset.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Sibsp & Parch","metadata":{}},{"cell_type":"code","source":"#Combine Sibsp & Parch\n#Write the code\ndataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Distribution of Family Population/Survival and Death\nfacet = sns.FacetGrid(dataset, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'FamilySize',shade= True)\nfacet.set(xlim=(0, dataset['FamilySize'].max()))\nfacet.add_legend()\nplt.xlim(0)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#The Mapping Function of Family Population \n#Write the code\nfamily_mapping = {1:0, 2:0.4, 3:0.8, 4:1.2, 5:1.6, 6:2, 7:2.4, 8:2.8, 9:3.2, 10:3.6, 11:4}\ndataset['FamilySize'] = dataset['FamilySize'].map(family_mapping)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Current dataframe\ndataset.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data Cleaning (資料清洗)","metadata":{}},{"cell_type":"code","source":"#Delete Sibsp, Parch, Ticket\n#Write the code\nfeatures_drop = ['Ticket', 'SibSp', 'Parch', 'PassengerId']\ndataset_hehe = dataset\ndataset = dataset.drop(features_drop, axis=1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Set Target Variables and Explanatory Variables\n#Write the code\ndataset_data = dataset.drop('Survived', axis=1)\n#survived為series(因為只有1 column), 加入括號轉為dataframe\ndataset_target = dataset[['Survived']]\ndataset_target.to_csv('dataset_target.csv')\nhehe = pd.DataFrame({\n    'PassengerId': dataset_hehe['PassengerId'],\n    'Survived': dataset['Survived']\n})\nhehe.to_csv('hehe.csv', index=False)\ndataset_data.shape, dataset_target.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#All explanatory variables\ndataset_data.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Check the types of every column in the training data.\n#They should be numeric type.\n#Write the code\ndataset_data.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Build the model-DNN","metadata":{}},{"cell_type":"code","source":"#Install keras, tensorflow\n#Write the code\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation  # 不需要 .core\nfrom keras.optimizers import Adam\nfrom sklearn import preprocessing\nimport tensorflow as tf","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def build_model():\n    #建立模型\n    model = Sequential()\n    #將模型疊起\n    model.add(Dense(input_dim=8, units=40))\n    model.add(Activation('relu'))\n    model.add(Dense(units=100))\n    model.add(Activation('relu'))\n    model.add(Dense(units=10))\n    model.add(Activation('relu'))\n    model.add(Dense(units=1))\n    model.add(Activation('sigmoid'))\n    model.summary()\n    return model","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Create a Drawing Function\ndef show_train_history(train_history, train, validation, label):\n    plt.plot(train_history.history[train])\n    plt.plot(train_history.history[validation])\n    plt.title('Train History')\n    plt.ylabel(label)\n    plt.xlabel('Epoch')\n    plt.legend(['train','validation'],loc='upper left')\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Feature Normalization\nminmax_scale = preprocessing.MinMaxScaler(feature_range=(0, 1))\nscaledFeatures = minmax_scale.fit_transform(dataset_data)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Train Model\nmodel = build_model()\nmodel.compile(loss = 'binary_crossentropy', optimizer='adam', metrics = ['acc'])\ntrain_history = model.fit(scaledFeatures, dataset_target, validation_split = 0.2, batch_size = 30, epochs = 40)\n#Evaluate training result\nscore = model.evaluate(x=scaledFeatures, y=dataset_target)\nprint('\\nTrain Loss:', score[0])\nprint('\\nTrain Acc:', score[1])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Show Training Process\n#Write the code\nshow_train_history(train_history, 'acc', 'val_acc', 'accuracy')\nshow_train_history(train_history, 'loss', 'val_loss', 'loss')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Test Model","metadata":{}},{"cell_type":"code","source":"#Preprocess the test data in the same way as the training data.\ntestdata = pd.read_csv('input/test-rosejack.csv')\n#Name\ntestdata['Title'] = testdata['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\ntitle_counts = testdata['Title'].value_counts()\ntitle_mapping = {\"Mr\": 0, \"Miss\": 1, \"Mrs\": 2, \"Master\": 3, \"Dr\": 3, \"Rev\": 3, \"Col\": 3, \"Major\": 3, \"Mlle\": 3, \"Countess\": 3, \"Ms\": 3, \"Lady\": 3, \"Jonkheer\": 3, \"Don\": 3, \"Dona\": 3, \"Mme\": 3, \"Capt\": 3, \"Sir\": 3}\ntestdata['Title'] = testdata['Title'].map(title_mapping)\ntestdata = testdata.drop('Name', axis=1) #已經drop過了所以再執行會錯誤\n#Sex\nsex_mapping = {'male': 0, 'female': 1}\ntestdata['Sex'] = testdata['Sex'].map(sex_mapping)\n#Age\ntestdata['Age'].fillna(testdata.groupby('Title')['Age'].transform('median'), inplace=True)\ntestdata.loc[ testdata['Age'] <= 16, 'Age'] = 0\ntestdata.loc[ (testdata['Age'] > 16) & (testdata['Age'] <= 26), 'Age'] = 1\ntestdata.loc[ (testdata['Age'] > 26) & (testdata['Age'] <= 36), 'Age'] = 2\ntestdata.loc[ (testdata['Age'] > 36) & (testdata['Age'] <= 62), 'Age'] = 3\ntestdata.loc[ testdata['Age'] > 62, 'Age'] = 4\n#Embarked\ntestdata['Embarked'] = testdata['Embarked'].fillna('S')\nembarked_mapping = {'S':0 , 'C':1, 'Q':2}\ntestdata['Embarked'] = testdata['Embarked'].map(embarked_mapping)\n#Fare\ntestdata['Fare'].fillna(testdata.groupby('Pclass')['Fare'].transform('median'),inplace=True)\ntestdata.loc[testdata['Fare']<=17, 'Fare'] = 0\ntestdata.loc[(testdata['Fare']>17) & (testdata['Fare'] <= 30), 'Fare'] = 1\ntestdata.loc[(testdata['Fare']>30) & (testdata['Fare'] <= 100), 'Fare'] = 2\ntestdata.loc[testdata['Fare']>100, 'Fare'] = 3\n#Cabin\ntestdata['Cabin'] = testdata['Cabin'].str[:1]\ncabin_mapping = {'A': 0, 'B': 0.4, 'C': 0.8, 'D': 1.2, 'E': 1.6, 'F': 2, 'G': 2.4, 'T': 2.8}\ntestdata['Cabin'] = testdata['Cabin'].map(cabin_mapping)\ntestdata['Cabin'].fillna(testdata.groupby('Pclass')['Cabin'].transform('median'), inplace=True)\n#FamilySize\ntestdata['FamilySize'] = testdata['SibSp'] + testdata['Parch'] + 1\nfamily_mapping = {1:0, 2:0.4, 3:0.8, 4:1.2, 5:1.6, 6:2, 7:2.4, 8:2.8, 9:3.2, 10:3.6, 11:4}\ntestdata['FamilySize'] = testdata['FamilySize'].map(family_mapping)\nfeatures_drop = ['Ticket', 'SibSp', 'Parch', 'PassengerId']\ntestdata = testdata.drop(features_drop, axis=1)\ntestdata.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#USe model.predict to predict the probability of survival\n#Write the code\nprobability = model.predict(testdata)\nprobability","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Obtain the weights of the model\n#Write the code\nw, b = model.layers[0].get_weights()\nprint('weights = {}, \\n\\n biases= {}'.format(w, b))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Save the model\n#Write the code\nmodel.save('dnnfortitanic.h5')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Kaggle Test.csv(DNN)(submission.csv提交至kaggel評分)","metadata":{}},{"cell_type":"code","source":"# Kaggle Test.csv\nimport pandas as pd\nimport numpy as np\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Activation\nfrom sklearn.preprocessing import MinMaxScaler\nimport joblib\n\n# 定義特徵列表\nfeatures = ['Pclass', 'Sex', 'Age', 'Fare', 'Embarked', 'Title', 'Cabin', 'FamilySize']\n\ndef build_model_test():\n    model = Sequential()\n    # 修改輸入維度為 8 (與特徵數量相同)\n    model.add(Dense(input_dim=8, units=40))\n    model.add(Activation('relu'))\n    model.add(Dense(units=100))\n    model.add(Activation('relu'))\n    model.add(Dense(units=10))\n    model.add(Activation('relu'))\n    model.add(Dense(units=1))\n    model.add(Activation('sigmoid'))\n    return model\n\n# 編譯模型\nmodel_test = build_model_test()\nmodel_test.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n\n# 確保訓練數據只包含我們要使用的特徵\nX_train = dataset_data[features]\n\n# 創建並擬合 scaler\nscaler = MinMaxScaler(feature_range=(0, 1))\nX_train_scaled = scaler.fit_transform(X_train)\n\n# 保存 scaler 供後續使用\njoblib.dump(scaler, 'scaler.save')\n\n# 訓練模型\ntrain_history = model_test.fit(X_train_scaled, dataset_target, \n                             validation_split=0.2, \n                             batch_size=30, \n                             epochs=40)\n\n# 保存模型\nmodel_test.save('model.h5')\n\n# 讀取測試數據\ntestdata_write = pd.read_csv('input/test.csv')\n\n# 特徵工程\n# Title 特徵\ntestdata_write['Title'] = testdata_write['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\ntitle_mapping = {\"Mr\": 0, \"Miss\": 1, \"Mrs\": 2, \"Master\": 3, \"Dr\": 3, \"Rev\": 3, \"Col\": 3, \n                \"Major\": 3, \"Mlle\": 3, \"Countess\": 3, \"Ms\": 3, \"Lady\": 3, \"Jonkheer\": 3, \n                \"Don\": 3, \"Dona\": 3, \"Mme\": 3, \"Capt\": 3, \"Sir\": 3}\ntestdata_write['Title'] = testdata_write['Title'].map(title_mapping)\n\n# Sex 特徵\ntestdata_write['Sex'] = testdata_write['Sex'].map({'male': 0, 'female': 1})\n\n# Age 特徵\ntestdata_write['Age'].fillna(testdata_write.groupby('Title')['Age'].transform('median'), inplace=True)\ntestdata_write.loc[testdata_write['Age'] <= 16, 'Age'] = 0\ntestdata_write.loc[(testdata_write['Age'] > 16) & (testdata_write['Age'] <= 26), 'Age'] = 1\ntestdata_write.loc[(testdata_write['Age'] > 26) & (testdata_write['Age'] <= 36), 'Age'] = 2\ntestdata_write.loc[(testdata_write['Age'] > 36) & (testdata_write['Age'] <= 62), 'Age'] = 3\ntestdata_write.loc[testdata_write['Age'] > 62, 'Age'] = 4\n\n# Embarked 特徵\ntestdata_write['Embarked'] = testdata_write['Embarked'].fillna('S')\ntestdata_write['Embarked'] = testdata_write['Embarked'].map({'S': 0, 'C': 1, 'Q': 2})\n\n# Fare 特徵\ntestdata_write['Fare'].fillna(testdata_write.groupby('Pclass')['Fare'].transform('median'), inplace=True)\ntestdata_write.loc[testdata_write['Fare'] <= 17, 'Fare'] = 0\ntestdata_write.loc[(testdata_write['Fare'] > 17) & (testdata_write['Fare'] <= 30), 'Fare'] = 1\ntestdata_write.loc[(testdata_write['Fare'] > 30) & (testdata_write['Fare'] <= 100), 'Fare'] = 2\ntestdata_write.loc[testdata_write['Fare'] > 100, 'Fare'] = 3\n\n# Cabin 特徵\ntestdata_write['Cabin'] = testdata_write['Cabin'].str[:1]\ncabin_mapping = {'A': 0, 'B': 0.4, 'C': 0.8, 'D': 1.2, 'E': 1.6, 'F': 2, 'G': 2.4, 'T': 2.8}\ntestdata_write['Cabin'] = testdata_write['Cabin'].map(cabin_mapping)\ntestdata_write['Cabin'].fillna(testdata_write.groupby('Pclass')['Cabin'].transform('median'), inplace=True)\n\n# FamilySize 特徵\ntestdata_write['FamilySize'] = testdata_write['SibSp'] + testdata_write['Parch'] + 1\nfamily_mapping = {1: 0, 2: 0.4, 3: 0.8, 4: 1.2, 5: 1.6, 6: 2, 7: 2.4, 8: 2.8, 9: 3.2, 10: 3.6, 11: 4}\ntestdata_write['FamilySize'] = testdata_write['FamilySize'].map(family_mapping)\n\n# 選擇要使用的特徵\nX_test = testdata_write[features]\n\n# 使用相同的 scaler 進行標準化\nX_test_scaled = scaler.transform(X_test)\n\n# 進行預測\nprobabilities = model_test.predict(X_test_scaled)\npredictions = (probabilities > 0.5).astype(int)\n\n# 創建提交文件\nsubmission = pd.DataFrame({\n    'PassengerId': testdata_write['PassengerId'],\n    'Survived': predictions.flatten()\n})\n\n# 保存結果\nsubmission.to_csv('submission.csv', index=False)\n\n# 檢查預測結果\nprint(\"Prediction distribution:\")\nprint(submission['Survived'].value_counts())\nprint(\"\\nSubmission file shape:\", submission.shape)\nprint(\"\\nFirst few predictions:\")\nprint(submission.head(30))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Kaggle Test.csv(KNN)(submission.csv提交至kaggel評分)","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import MinMaxScaler\nimport joblib\n\n# 定義特徵列表\nfeatures = ['Pclass', 'Sex', 'Age', 'Fare', 'Embarked', 'Title', 'Cabin', 'FamilySize']\n\n# 讀取訓練數據\nX_train = dataset_data[features]\ny_train = dataset_target\n# 創建並擬合 scaler\nscaler = MinMaxScaler(feature_range=(0, 1))\nX_train_scaled = scaler.fit_transform(X_train)\n\n# 保存 scaler 供後續使用\njoblib.dump(scaler, 'scalerkNN.save')\n\n# 創建並訓練 KNN 模型\nknn_model = KNeighborsClassifier(n_neighbors=5)  # 可以調整 n_neighbors 的值\nknn_model.fit(X_train_scaled, y_train)\n\n# 保存模型\njoblib.dump(knn_model, 'knn_model.save')\n\n# 讀取測試數據\ntestdata_write = pd.read_csv('input/test.csv')\n\n# 特徵工程（保持不變）\n# Title 特徵\ntestdata_write['Title'] = testdata_write['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\ntitle_mapping = {\"Mr\": 0, \"Miss\": 1, \"Mrs\": 2, \"Master\": 3, \"Dr\": 3, \"Rev\": 3, \"Col\": 3, \n                \"Major\": 3, \"Mlle\": 3, \"Countess\": 3, \"Ms\": 3, \"Lady\": 3, \"Jonkheer\": 3, \n                \"Don\": 3, \"Dona\": 3, \"Mme\": 3, \"Capt\": 3, \"Sir\": 3}\ntestdata_write['Title'] = testdata_write['Title'].map(title_mapping)\n\n# Sex 特徵\ntestdata_write['Sex'] = testdata_write['Sex'].map({'male': 0, 'female': 1})\n\n# Age 特徵\ntestdata_write['Age'].fillna(testdata_write.groupby('Title')['Age'].transform('median'), inplace=True)\ntestdata_write.loc[testdata_write['Age'] <= 16, 'Age'] = 0\ntestdata_write.loc[(testdata_write['Age'] > 16) & (testdata_write['Age'] <= 26), 'Age'] = 1\ntestdata_write.loc[(testdata_write['Age'] > 26) & (testdata_write['Age'] <= 36), 'Age'] = 2\ntestdata_write.loc[(testdata_write['Age'] > 36) & (testdata_write['Age'] <= 62), 'Age'] = 3\ntestdata_write.loc[testdata_write['Age'] > 62, 'Age'] = 4\n\n# Embarked 特徵\ntestdata_write['Embarked'] = testdata_write['Embarked'].fillna('S')\ntestdata_write['Embarked'] = testdata_write['Embarked'].map({'S': 0, 'C': 1, 'Q': 2})\n\n# Fare 特徵\ntestdata_write['Fare'].fillna(testdata_write.groupby('Pclass')['Fare'].transform('median'), inplace=True)\ntestdata_write.loc[testdata_write['Fare'] <= 17, 'Fare'] = 0\ntestdata_write.loc[(testdata_write['Fare'] > 17) & (testdata_write['Fare'] <= 30), 'Fare'] = 1\ntestdata_write.loc[(testdata_write['Fare'] > 30) & (testdata_write['Fare'] <= 100), 'Fare'] = 2\ntestdata_write.loc[testdata_write['Fare'] > 100, 'Fare'] = 3\n\n# Cabin 特徵\ntestdata_write['Cabin'] = testdata_write['Cabin'].str[:1]\ncabin_mapping = {'A': 0, 'B': 0.4, 'C': 0.8, 'D': 1.2, 'E': 1.6, 'F': 2, 'G': 2.4, 'T': 2.8}\ntestdata_write['Cabin'] = testdata_write['Cabin'].map(cabin_mapping)\ntestdata_write['Cabin'].fillna(testdata_write.groupby('Pclass')['Cabin'].transform('median'), inplace=True)\n\n# FamilySize 特徵\ntestdata_write['FamilySize'] = testdata_write['SibSp'] + testdata_write['Parch'] + 1\nfamily_mapping = {1: 0, 2: 0.4, 3: 0.8, 4: 1.2, 5: 1.6, 6: 2, 7: 2.4, 8: 2.8, 9: 3.2, 10: 3.6, 11: 4}\ntestdata_write['FamilySize'] = testdata_write['FamilySize'].map(family_mapping)\n\n# 選擇要使用的特徵\nX_test = testdata_write[features]\n\n# 使用相同的 scaler 進行標準化\nX_test_scaled = scaler.transform(X_test)\n\n# 進行預測\npredictions = knn_model.predict(X_test_scaled)\n\n# 創建提交文件\nsubmission = pd.DataFrame({\n    'PassengerId': testdata_write['PassengerId'],\n    'Survived': predictions\n})\n\n# 保存結果\nsubmission.to_csv('submission(KNN).csv', index=False)\n\n# 檢查預測結果\nprint(\"Prediction distribution:\")\nprint(submission['Survived'].value_counts())\nprint(\"\\nSubmission file shape:\", submission.shape)\nprint(\"\\nFirst few predictions:\")\nprint(submission.head())\n\n# 評估模型在訓練集上的表現\ntrain_accuracy = knn_model.score(X_train_scaled, y_train)\nprint(f\"\\nTraining Accuracy: {train_accuracy:.4f}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Kaggle Test.scv(SVM)(submission.csv提交至kaggel評分)","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.svm import SVC\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import cross_val_score\nimport joblib\n\n# 定義特徵列表\nfeatures = ['Pclass', 'Sex', 'Age', 'Fare', 'Embarked', 'Title', 'Cabin', 'FamilySize']\n\n# 讀取訓練數據\nX_train = dataset_data[features]\ny_train = dataset_target\n\n# 創建並擬合 scaler\nscaler = MinMaxScaler(feature_range=(0, 1))\nX_train_scaled = scaler.fit_transform(X_train)\n\n# 保存 scaler 供後續使用\njoblib.dump(scaler, 'scaler.save')\n\n# 創建並訓練 SVM 模型\nsvm_model = SVC(kernel='rbf',  # 可以選擇 'linear', 'poly', 'rbf', 'sigmoid'\n                C=1.0,         # 正則化參數\n                probability=True)\n\n# 使用交叉驗證評估模型\ncv_scores = cross_val_score(svm_model, X_train_scaled, y_train, cv=5)\nprint(f\"Cross-validation scores: {cv_scores}\")\nprint(f\"Average CV score: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n\n# 在完整訓練集上訓練模型\nsvm_model.fit(X_train_scaled, y_train)\n\n# 保存模型\njoblib.dump(svm_model, 'svm_model.save')\n\n# 讀取測試數據\ntestdata_write = pd.read_csv('input/test.csv')\n\n# 特徵工程\n# Title 特徵\ntestdata_write['Title'] = testdata_write['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\ntitle_mapping = {\"Mr\": 0, \"Miss\": 1, \"Mrs\": 2, \"Master\": 3, \"Dr\": 3, \"Rev\": 3, \"Col\": 3, \n                \"Major\": 3, \"Mlle\": 3, \"Countess\": 3, \"Ms\": 3, \"Lady\": 3, \"Jonkheer\": 3, \n                \"Don\": 3, \"Dona\": 3, \"Mme\": 3, \"Capt\": 3, \"Sir\": 3}\ntestdata_write['Title'] = testdata_write['Title'].map(title_mapping)\n\n# Sex 特徵\ntestdata_write['Sex'] = testdata_write['Sex'].map({'male': 0, 'female': 1})\n\n# Age 特徵\ntestdata_write['Age'].fillna(testdata_write.groupby('Title')['Age'].transform('median'), inplace=True)\ntestdata_write.loc[testdata_write['Age'] <= 16, 'Age'] = 0\ntestdata_write.loc[(testdata_write['Age'] > 16) & (testdata_write['Age'] <= 26), 'Age'] = 1\ntestdata_write.loc[(testdata_write['Age'] > 26) & (testdata_write['Age'] <= 36), 'Age'] = 2\ntestdata_write.loc[(testdata_write['Age'] > 36) & (testdata_write['Age'] <= 62), 'Age'] = 3\ntestdata_write.loc[testdata_write['Age'] > 62, 'Age'] = 4\n\n# Embarked 特徵\ntestdata_write['Embarked'] = testdata_write['Embarked'].fillna('S')\ntestdata_write['Embarked'] = testdata_write['Embarked'].map({'S': 0, 'C': 1, 'Q': 2})\n\n# Fare 特徵\ntestdata_write['Fare'].fillna(testdata_write.groupby('Pclass')['Fare'].transform('median'), inplace=True)\ntestdata_write.loc[testdata_write['Fare'] <= 17, 'Fare'] = 0\ntestdata_write.loc[(testdata_write['Fare'] > 17) & (testdata_write['Fare'] <= 30), 'Fare'] = 1\ntestdata_write.loc[(testdata_write['Fare'] > 30) & (testdata_write['Fare'] <= 100), 'Fare'] = 2\ntestdata_write.loc[testdata_write['Fare'] > 100, 'Fare'] = 3\n\n# Cabin 特徵\ntestdata_write['Cabin'] = testdata_write['Cabin'].str[:1]\ncabin_mapping = {'A': 0, 'B': 0.4, 'C': 0.8, 'D': 1.2, 'E': 1.6, 'F': 2, 'G': 2.4, 'T': 2.8}\ntestdata_write['Cabin'] = testdata_write['Cabin'].map(cabin_mapping)\ntestdata_write['Cabin'].fillna(testdata_write.groupby('Pclass')['Cabin'].transform('median'), inplace=True)\n\n# FamilySize 特徵\ntestdata_write['FamilySize'] = testdata_write['SibSp'] + testdata_write['Parch'] + 1\nfamily_mapping = {1: 0, 2: 0.4, 3: 0.8, 4: 1.2, 5: 1.6, 6: 2, 7: 2.4, 8: 2.8, 9: 3.2, 10: 3.6, 11: 4}\ntestdata_write['FamilySize'] = testdata_write['FamilySize'].map(family_mapping)\n\n# 選擇要使用的特徵\nX_test = testdata_write[features]\n\n# 使用相同的 scaler 進行標準化\nX_test_scaled = scaler.transform(X_test)\n\n# 進行預測\npredictions = svm_model.predict(X_test_scaled)\n\n# 預測機率\nprobabilities = svm_model.predict_proba(X_test_scaled)\n\n# 創建提交文件\nsubmission = pd.DataFrame({\n    'PassengerId': testdata_write['PassengerId'],\n    'Survived': predictions\n})\n\n# 保存結果\nsubmission.to_csv('submission(SVM).csv', index=False)\n\n# 檢查預測結果\nprint(\"\\nPrediction distribution:\")\nprint(submission['Survived'].value_counts())\nprint(\"\\nSubmission file shape:\", submission.shape)\nprint(\"\\nFirst few predictions:\")\nprint(submission.head())\n\n# 評估模型在訓練集上的表現\ntrain_accuracy = svm_model.score(X_train_scaled, y_train)\nprint(f\"\\nTraining Accuracy: {train_accuracy:.4f}\")\n\n# 顯示前幾個預測的概率\nprint(\"\\nFirst few prediction probabilities:\")\nprint(probabilities[:30])\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Kaggle Test.scv(Random Forest)(submission.csv提交至kaggel評分)","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import cross_val_score\nimport joblib\nimport matplotlib.pyplot as plt\n\n# 定義特徵列表\nfeatures = ['Pclass', 'Sex', 'Age', 'Fare', 'Embarked', 'Title', 'Cabin', 'FamilySize']\n\n# 讀取訓練數據\nX_train = dataset_data[features]\ny_train = dataset_target\n\n# 創建並擬合 scaler\nscaler = MinMaxScaler(feature_range=(0, 1))\nX_train_scaled = scaler.fit_transform(X_train)\n\n# 保存 scaler 供後續使用\njoblib.dump(scaler, 'scaler.save')\n\n# 創建並訓練 Random Forest 模型\nrf_model = RandomForestClassifier(\n    n_estimators=100,    # 樹的數量\n    max_depth=None,      # 樹的最大深度\n    min_samples_split=2, # 分裂節點所需的最小樣本數\n    min_samples_leaf=1,  # 葉節點所需的最小樣本數\n    random_state=42      # 隨機種子，確保結果可重現\n)\n\n# 使用交叉驗證評估模型\ncv_scores = cross_val_score(rf_model, X_train_scaled, y_train, cv=5)\nprint(f\"Cross-validation scores: {cv_scores}\")\nprint(f\"Average CV score: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n\n# 在完整訓練集上訓練模型\nrf_model.fit(X_train_scaled, y_train)\n\n# 保存模型\njoblib.dump(rf_model, 'rf_model.save')\n\n# 讀取測試數據\ntestdata_write = pd.read_csv('input/test.csv')\n\n# Feature Engineering\n# Title 特徵\ntestdata_write['Title'] = testdata_write['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\ntitle_mapping = {\"Mr\": 0, \"Miss\": 1, \"Mrs\": 2, \"Master\": 3, \"Dr\": 3, \"Rev\": 3, \"Col\": 3, \n                \"Major\": 3, \"Mlle\": 3, \"Countess\": 3, \"Ms\": 3, \"Lady\": 3, \"Jonkheer\": 3, \n                \"Don\": 3, \"Dona\": 3, \"Mme\": 3, \"Capt\": 3, \"Sir\": 3}\ntestdata_write['Title'] = testdata_write['Title'].map(title_mapping)\n\n# Sex 特徵\ntestdata_write['Sex'] = testdata_write['Sex'].map({'male': 0, 'female': 1})\n\n# Age 特徵\ntestdata_write['Age'].fillna(testdata_write.groupby('Title')['Age'].transform('median'), inplace=True)\ntestdata_write.loc[testdata_write['Age'] <= 16, 'Age'] = 0\ntestdata_write.loc[(testdata_write['Age'] > 16) & (testdata_write['Age'] <= 26), 'Age'] = 1\ntestdata_write.loc[(testdata_write['Age'] > 26) & (testdata_write['Age'] <= 36), 'Age'] = 2\ntestdata_write.loc[(testdata_write['Age'] > 36) & (testdata_write['Age'] <= 62), 'Age'] = 3\ntestdata_write.loc[testdata_write['Age'] > 62, 'Age'] = 4\n\n# Embarked 特徵\ntestdata_write['Embarked'] = testdata_write['Embarked'].fillna('S')\ntestdata_write['Embarked'] = testdata_write['Embarked'].map({'S': 0, 'C': 1, 'Q': 2})\n\n# Fare 特徵\ntestdata_write['Fare'].fillna(testdata_write.groupby('Pclass')['Fare'].transform('median'), inplace=True)\ntestdata_write.loc[testdata_write['Fare'] <= 17, 'Fare'] = 0\ntestdata_write.loc[(testdata_write['Fare'] > 17) & (testdata_write['Fare'] <= 30), 'Fare'] = 1\ntestdata_write.loc[(testdata_write['Fare'] > 30) & (testdata_write['Fare'] <= 100), 'Fare'] = 2\ntestdata_write.loc[testdata_write['Fare'] > 100, 'Fare'] = 3\n\n# Cabin 特徵\ntestdata_write['Cabin'] = testdata_write['Cabin'].str[:1]\ncabin_mapping = {'A': 0, 'B': 0.4, 'C': 0.8, 'D': 1.2, 'E': 1.6, 'F': 2, 'G': 2.4, 'T': 2.8}\ntestdata_write['Cabin'] = testdata_write['Cabin'].map(cabin_mapping)\ntestdata_write['Cabin'].fillna(testdata_write.groupby('Pclass')['Cabin'].transform('median'), inplace=True)\n\n# FamilySize 特徵\ntestdata_write['FamilySize'] = testdata_write['SibSp'] + testdata_write['Parch'] + 1\nfamily_mapping = {1: 0, 2: 0.4, 3: 0.8, 4: 1.2, 5: 1.6, 6: 2, 7: 2.4, 8: 2.8, 9: 3.2, 10: 3.6, 11: 4}\ntestdata_write['FamilySize'] = testdata_write['FamilySize'].map(family_mapping)\n\n# 選擇要使用的特徵\nX_test = testdata_write[features]\n\n# 使用相同的 scaler 進行標準化\nX_test_scaled = scaler.transform(X_test)\n\n# 進行預測\npredictions = rf_model.predict(X_test_scaled)\nprobabilities = rf_model.predict_proba(X_test_scaled)\n\n# 創建提交文件\nsubmission = pd.DataFrame({\n    'PassengerId': testdata_write['PassengerId'],\n    'Survived': predictions\n})\n\n# 保存結果\nsubmission.to_csv('submission(Random Forest).csv', index=False)\n\n# 檢查預測結果\nprint(\"\\nPrediction distribution:\")\nprint(submission['Survived'].value_counts())\nprint(\"\\nSubmission file shape:\", submission.shape)\nprint(\"\\nFirst few predictions:\")\nprint(submission.head())\n\n# 評估模型在訓練集上的表現\ntrain_accuracy = rf_model.score(X_train_scaled, y_train)\nprint(f\"\\nTraining Accuracy: {train_accuracy:.4f}\")\n\n# 顯示特徵重要性\nfeature_importance = pd.DataFrame({\n    'feature': features,\n    'importance': rf_model.feature_importances_\n})\nfeature_importance = feature_importance.sort_values('importance', ascending=False)\nprint(\"\\nFeature Importance:\")\nprint(feature_importance)\n\n# 繪製特徵重要性圖表\nplt.figure(figsize=(10, 6))\nplt.bar(feature_importance['feature'], feature_importance['importance'])\nplt.xticks(rotation=45)\nplt.title('Feature Importance in Random Forest Model')\nplt.tight_layout()\nplt.show()\n\n# 顯示前幾個預測的概率\nprint(\"\\nFirst few prediction probabilities:\")\nprint(probabilities[:5])\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}